# ðŸ¤– Agentic AI + MLOps Pipeline with LangChain, Ollama, and MLflow

A production-ready, end-to-end pipeline that combines **Agentic AI workflows** and **modern MLOps practices** using **LangChain**, **Ollama**, **ChromaDB**, **MLflow**, and **Streamlit**.

This project supports intelligent PDF-based assistants using RAG (Retrieval-Augmented Generation), tool-based agents, evaluation, logging, and a beautiful UI.

---

## ðŸ§  Key Features

- ðŸ” PDF Ingestion + Chroma Vector Store
- ðŸ¤– RAG-based QA with Ollama LLMs (Mistral, LLaMA2, etc.)
- ðŸ§  Agentic Pipeline with LangGraph + Tools + Memory
- ðŸ“Š LLM Monitoring with MLflow
- ðŸ§ª Evaluation with cosine similarity scoring
- ðŸ–¼ï¸ Streamlit Chatbot UI
- ðŸ³ Dockerized for deployment

---

## ðŸ“ Project Structure

.
â”œâ”€â”€ 01_ingestion/               # Load PDF â†’ Chunk â†’ Embed â†’ Store
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ ingest.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ data/                   # Holds raw PDFs
â”‚   â”œâ”€â”€ embeddings/             # ChromaDB vector index
â”‚   â”œâ”€â”€ query.py                # Simple RAG-based QA
â”‚   â”œâ”€â”€ ui.py                   # Streamlit chatbot
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ 02_agent_pipeline/         # Agentic reasoning pipeline
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ chatbot_agent.py    # LangGraph + Tools + Memory
â”‚   â”‚   â””â”€â”€ test_agent.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ 06_monitoring_mlflow/      # LLM monitoring + logging
â”‚   â”œâ”€â”€ log_utils.py
â”‚   â”œâ”€â”€ track_run.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ mlruns/                 # Auto-generated MLflow run logs
â”‚
â”œâ”€â”€ 07_evaluation/             # RAG response evaluation
â”‚   â”œâ”€â”€ eval_config.yaml
â”‚   â”œâ”€â”€ evaluate_rag.py
â”‚   â”œâ”€â”€ evaluation_utils.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ Dockerfile                 # Streamlit + Ollama Docker config
â””â”€â”€ README.md                  # Youâ€™re reading it!

# Setup Instructions

# 1. Clone the repository
git clone https://github.com/AnantKrishna1/genai-agentic-mlops.git
cd genai-agentic-mlops

# 2. (Optional) Create a virtual environment
conda create -n genai-rag python=3.10 -y
conda activate genai-rag

# 3. Install base requirements
pip install -r 01_ingestion/requirements.txt

# 4. Download and run an Ollama model (e.g. Mistral)
ollama run mistral

# Here are detailed steps:

# 1 PDF Ingestion & Vector Store

# Copy your PDF to the data/ folder
cp sample.pdf 01_ingestion/data/

# Run the embedding pipeline
cd 01_ingestion/app
python ingest.py

âœ… Output: Document is split, embedded with SentenceTransformer, and stored in ChromaDB under embeddings/.

# Query with RAG

# Still in 01_ingestion/
python query.py

 âœ… Ask questions like:

What is the main purpose of the PDF?

# Streamlit Chatbot UI

streamlit run ui.py

âœ… An interactive chatbot powered by RAG + Ollama will launch in your browser.

# Agentic Pipeline with LangGraph

# Inside 02_agent_pipeline/
python app/chatbot_agent.py

âœ… Features:

LangGraph-powered memory chain

AgentTools (math, search, file reader)

Conversational context handling

# LLM Monitoring with MLflow

# Inside 06_monitoring_mlflow/
python track_run.py

âœ… Tracks:

User queries

LLM responses

Latency

Accuracy

ðŸ” View MLflow UI: mlflow ui

# Evaluation & Benchmarking

# Inside 07_evaluation/
python evaluate_rag.py

âœ… Performs:

Cosine similarity scoring

Latency tracking

Pass/Fail based on a custom YAML test set

# Docker Deployment
Dockerfile handles Ollama setup + Streamlit UI.

# Optional: Run Ollama container (Mistral)
docker run -d -p 11434:11434 ollama/ollama mistral

# Build and run the chatbot
docker build -t genai-chatbot .
docker run -p 8501:8501 genai-chatbot

Sample Output

ðŸ”¹ Question: What is the main goal of the document?
ðŸ“¤ Model Answer: The document aims to test the ingestion pipeline in an Agentic AI + MLOps project.
âœ… Expected: The document is for testing the ingestion pipeline...
â±ï¸ Response Time: 2.7 seconds
ðŸ“Š Similarity Score: 0.87
ðŸŸ¢ PASSED


# Technologies Used
Category	Tools & Libraries
LLMs	Mistral (via Ollama), LLaMA2, Gemma
Vector DB	ChromaDB + SentenceTransformers
Frameworks	LangChain, LangGraph
Monitoring	MLflow
Frontend	Streamlit
Packaging	Docker

# Conceptual Workflow

graph TD
    A[PDF] --> B[Chunk + Embed]
    B --> C[Chroma VectorDB]
    C --> D[Query Engine / Agent]
    D --> E[LLM (Ollama)]
    E --> F[Answer]
    D --> G[MLflow Logs]
    D --> H[Evaluator]
